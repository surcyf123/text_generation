MODELS_INFO = {
    "gpt4-x-vicuna-13B-GPTQ": {
        "model_file": "model",
        "model_dir": "/home/betogaona7/text_generation/benchmark/assets/quantized_models/gpt4-x-vicuna-13B-GPTQ",
    }
}
